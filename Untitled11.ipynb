{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRLzjOv9KrU5T2iA17HCmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niralakumar/practice/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "List_Of_employees=[]\n",
        "\n",
        "for i in data:\n",
        "    sub_dept=''\n",
        "    if i ['EMPLOYEE']['sub_department'] is None:\n",
        "        sub_dept=''\n",
        "\n",
        "    else:\n",
        "        print(\"2\")\n",
        "        print(i ['EMPLOYEE']['sub_department'])\n",
        "        print(type(i ['EMPLOYEE']['sub_department']))\n",
        "        sub_dept=str(i ['EMPLOYEE']['sub_department'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    List_Of_employees.append([i ['EMPLOYEE']['full_name'],i ['EMPLOYEE']['employee_id'],i ['EMPLOYEE']['date_of_joining'],i ['EMPLOYEE']['date_of_birth'],i ['EMPLOYEE']['phone'],i ['EMPLOYEE']['location_custom'],i ['EMPLOYEE']['gender'],i ['EMPLOYEE']['grade'],i ['EMPLOYEE']['designation'],i ['EMPLOYEE']['email_address'],i ['EMPLOYEE']['band_name'],i ['EMPLOYEE']['region'],i ['EMPLOYEE']['city'],i ['EMPLOYEE']['state'],i ['EMPLOYEE']['country'],i ['EMPLOYEE']['division'],i ['EMPLOYEE']['job_location'],i ['EMPLOYEE']['work_location_code'],i ['EMPLOYEE']['cost_name'],i ['EMPLOYEE']['role_name'],i ['EMPLOYEE']['employee_class'],i ['EMPLOYEE']['branch_name'],i ['EMPLOYEE']['department'],sub_dept,i ['EMPLOYEE']['business_unit'],i ['EMPLOYEE']['sub_business_unit'],i ['EMPLOYEE']['status'],i ['EMPLOYEE']['supervisor_code'],i ['EMPLOYEE']['supervisor_name'],i ['EMPLOYEE']['supervisor_email_address'],i ['EMPLOYEE']['functional_manager_code'],i ['EMPLOYEE']['functional_manager_name'],i ['EMPLOYEE']['functional_manager_email_address'],i ['EMPLOYEE']['last_transaction_date'],i ['EMPLOYEE']['last_working_day']])\n"
      ],
      "metadata": {
        "id": "rpz3Ht-qs6Mz",
        "outputId": "e36b34b1-4445-40db-e583-09af2a084d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b42c516a86b2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mList_Of_employees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msub_dept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'EMPLOYEE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub_department'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"try spark\").getOrCreate()\n",
        "# df=spark.read.csv('/content/origfile.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "XXTb102WrfmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta,datetime\n",
        "today = datetime.now()+ timedelta(days=-3)\n",
        "DateFormat= today.strftime('%Y%m')\n",
        "print(DateFormat)\n",
        "\n",
        "df=spark.sql(\"\"\"select * from (select current_date,'astp'as tp union all select current_date,'bstp' as tp) where 1=0\"\"\")\n",
        "print(df)\n",
        "df.show()\n",
        "dfc=df.count()\n",
        "print(dfc)\n",
        "df1=df.isEmpty()\n",
        "print(df1)\n",
        "print(df.head(2))\n",
        "df.rdd.isEmpty()\n",
        "print(len(df.head(2)))\n"
      ],
      "metadata": {
        "id": "PLpju0Q8yCNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base URL-->Admitcard | Scholarships Exam\n",
        "# Append token using below logic\n",
        "# token= <RollNo>+'###'+<DOB>\n",
        "# Blob beforeblob = Blob.valueOf(token);\n",
        "# String tokenId = EncodingUtil.base64Encode(beforeblob);\n",
        "# https://anthe.aakash.ac.in/exam/admitcard?token=+tokenId;\n",
        "\n",
        "import base64\n",
        "\n",
        "sample_string = \"GeeksForGeeks is the best\"\n",
        "sample_string_bytes = sample_string.encode(\"ascii\")\n",
        "print(sample_string_bytes)\n"
      ],
      "metadata": {
        "id": "WqNWVkzde0nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find minimum and maximum elements in an array\n",
        "def find_min_max(arr):\n",
        "    if not arr:\n",
        "        return None, None  # If the array is empty, return None for both min and max\n",
        "\n",
        "    # Initialize min and max with the first element of the array\n",
        "    min_element = max_element = arr[0]\n",
        "\n",
        "    # Iterate through the array to find the minimum and maximum elements\n",
        "    for element in arr:\n",
        "        if element < min_element:\n",
        "            min_element = element\n",
        "        elif element > max_element:\n",
        "            max_element = element\n",
        "\n",
        "    return min_element, max_element\n",
        "\n",
        "# Input: Take space-separated integers as input and convert them into a list\n",
        "try:\n",
        "    input_array = list(map(int, input(\"Enter elements of the array separated by space: \").split()))\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter integers separated by space.\")\n",
        "    exit()\n",
        "\n",
        "# Find and print the minimum and maximum elements\n",
        "min_val, max_val = find_min_max(input_array)\n",
        "\n",
        "if min_val is not None and max_val is not None:\n",
        "    print(\"Minimum element:\", min_val)\n",
        "    print(\"Maximum element:\", max_val)\n",
        "else:\n",
        "    print(\"Array is empty.\")\n"
      ],
      "metadata": {
        "id": "l9dspn818EMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=input().split()\n",
        "s_arr=s.split()\n",
        "print(s_arr)\n"
      ],
      "metadata": {
        "id": "fNfqyNmy8gio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Extract year, month, and day components\n",
        "year = current_date.year\n",
        "month = current_date.month\n",
        "day = current_date.day\n",
        "\n",
        "# Format the date as YYYYMD (without leading zeros in the month and day)\n",
        "formatted_date = f\"{year}{month}{day}\"\n",
        "\n",
        "# Print the formatted date\n",
        "print(formatted_date)\n"
      ],
      "metadata": {
        "id": "kLveg-lpsrBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Extract year, month, and day components\n",
        "year = current_date.year\n",
        "month = current_date.month\n",
        "day = current_date.day\n",
        "\n",
        "# Format the date as YYYYMDD (without leading zero in the month)\n",
        "formatted_date = f\"{year}{month}{day:02}\"\n",
        "\n",
        "# Print the formatted date\n",
        "print(formatted_date)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ni_sdnd-sVNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Format the date as YYYYMDD (without leading zero in the month)\n",
        "formatted_date = current_date.strftime(\"%Y%m%d\").lstrip(\"0\")\n",
        "\n",
        "# Print the formatted date\n",
        "print(formatted_date)\n"
      ],
      "metadata": {
        "id": "NmIGl5GFsLWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s='pserp-full-load-tables-for-derived-tables-psquery-daily/SYSADM/PS_AES_CROFR_AUDIT_VW/LOAD00000001.parquet'\n",
        "# print(\"objectkey\",object_key)\n",
        "b=s.find('/',s.find('/')+1)\n",
        "print(b)\n",
        "\n",
        "f=s.find('/',b)\n",
        "print(f)\n",
        "File_name_wo_path=s[f+1:]\n",
        "print(File_name_wo_path)\n",
        "# obj = s3.Object(source_bucket, object_key)\n",
        "# current_date = datetime.now().date()\n",
        "# year_=str(current_date.year)\n",
        "# month_=str(current_date.month)\n",
        "# day_=str(current_date.day)\n",
        "# if 'result' in object_key.lower():\n",
        "#     f=object_key.find('/',b+1)\n",
        "#     print(f)\n",
        "#     File_name_wo_path=object_key[f+1:]\n",
        "#     destination_key=\"Migrated_Data/SOE_version_2/results/\"+year_+'/'+month_+'/'+day_+'/'+File_name_wo_path"
      ],
      "metadata": {
        "id": "coeHvXBUm73T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=\"ansdj\"\n",
        "if a==\"ansdj\":\n",
        "  print(\"te\")"
      ],
      "metadata": {
        "id": "xUbdWs9oJHl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime,date\n",
        "from datetime import timedelta\n",
        "from datetime import *\n",
        "i = 0\n",
        "j= 111\n",
        "for x in range(j+1):\n",
        "    if i>111:\n",
        "        break\n",
        "    else:\n",
        "        y = 0\n",
        "        y = j - i;\n",
        "        Date_req = date.today() - timedelta(days=y)\n",
        "        Dated=Date_req.strftime(\"%-Y/%-m/Day=%-d\")\n",
        "        Datedy=Date_req.strftime(\"%Y\")\n",
        "        # print(Datedy)\n",
        "        Datedm=Date_req.strftime(\"%m\")\n",
        "        # print(Datedm)\n",
        "        Datedd=Date_req.strftime(\"%d\")\n",
        "        # print(Datedd)\n",
        "        # print(\"Range\",x, \"Second Date\", Dated)\n",
        "        i = i+1\n",
        "# y = j - i\n",
        "# Date_req = date.today() - timedelta(days=y)\n",
        "# print(Date_req)"
      ],
      "metadata": {
        "id": "b9wa2qnsXs4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create some data\n",
        "data = {'Name': ['John', 'Emma', 'Brad', 'Susan'],\n",
        "        'Age': [25, 30, 28, 35],\n",
        "        'Gender': ['M', 'F', 'M', 'F']}\n",
        "\n",
        "# create the dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# create a new column using an expression\n",
        "df = df.assign(AgePlusTen=df['Age'] + 10).assign(AgePlusTens=df['Age'] + 10)\n",
        "\n",
        "# print the dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "WZ9Zoe_vZL6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create some data\n",
        "data = {'Name': ['John', 'Emma', 'Brad', 'Susan'],\n",
        "        'Gender': ['M', 'F', 'M', 'F'],\n",
        "        'Age': [25, 30, 28, 35],\n",
        "        'Salary': [50000, 60000, 55000, 70000]}\n",
        "\n",
        "# create the dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# group the dataframe by Gender\n",
        "grouped = df.groupby('Gender')\n",
        "\n",
        "# calculate the average salary for each gender\n",
        "result = grouped['Salary'].mean()\n",
        "\n",
        "# print the result\n",
        "print(result)"
      ],
      "metadata": {
        "id": "9a4DnVIpC73p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyspark\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "import json\n",
        "import sys\n",
        "from json import loads\n",
        "import requests\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col,expr\n",
        "\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import md5, concat_ws, col, udf, lit, coalesce, to_timestamp, trim\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import col,expr\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "today1=datetime.now() + timedelta(days=-121)\n",
        "# today1=datetime.now() + timedelta(days=-3)\n",
        "years1=today1.strftime('%Y')\n",
        "months1=today1.strftime('%m')\n",
        "days_12=today1.strftime('%d')\n",
        "todays_date=today1.strftime('%Y-%m-%d')\n",
        "print(todays_date)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p2d3q8mvUS2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import ChainMap\n",
        "fruit_colour_mapping = [{'apple': 'red'}, {'banana': 'yellow'}]\n",
        "final_map = ChainMap(*fruit_colour_mapping)\n",
        "\n",
        "\n",
        "# print key value pairs:\n",
        "for element in final_map.items():\n",
        "    print(element)\n",
        "\n",
        "# change a value:\n",
        "final_map['banana'] = 'green'    # supermarkets these days....\n",
        "\n",
        "# access by key:\n",
        "print(final_map['banana'])"
      ],
      "metadata": {
        "id": "a6oRXpeMc5jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[\n",
        "   {\n",
        "      \"Arn\":\"arn:aws:quicksight:ap-south-1:910393621111:group/default/testgroup\",\n",
        "      \"GroupName\":\"testgroup\",\n",
        "      \"PrincipalId\":\"group/d-9f673c79a6/b472b0dd-92f6-4dad-a02d-e4ef636594c8\"\n",
        "   },\n",
        "   {\n",
        "      \"Arn\":\"arn:aws:quicksight:ap-south-1:910393621111:group/default/AI_FR_MANAGER\",\n",
        "      \"GroupName\":\"AI_FR_MANAGER\",\n",
        "      \"Description\":\"AI_FR_MANAGER\",\n",
        "      \"PrincipalId\":\"group/d-9f673c79a6/d0bb9d3d-865c-4cb2-b2b9-3ccc67f8de83\"\n",
        "   },\n",
        "   {\n",
        "      \"Arn\":\"arn:aws:quicksight:ap-south-1:910393621111:group/default/AES_SF_DATA_CONVERSION\",\n",
        "      \"GroupName\":\"AES_SF_DATA_CONVERSION\",\n",
        "      \"Description\":\"AES_SF_DATA_CONVERSION\",\n",
        "      \"PrincipalId\":\"group/d-9f673c79a6/c2f44225-4166-471b-8c6d-6061f5f7e5dc\"\n",
        "   },\n",
        "   {\n",
        "      \"Arn\":\"arn:aws:quicksight:ap-south-1:910393621111:group/default/Job_Requisition_Authorizor\",\n",
        "      \"GroupName\":\"Job_Requisition_Authorizor\",\n",
        "      \"Description\":\"Job_Requisition_Authorizor\",\n",
        "      \"PrincipalId\":\"group/d-9f673c79a6/9a879c53-9c9d-4eef-bd15-c1e1a7a2e438\"\n",
        "   },\n",
        "   {\n",
        "      \"Arn\":\"arn:aws:quicksight:ap-south-1:910393621111:group/default/AI_BR_VIRTUAL_CLASS\",\n",
        "      \"GroupName\":\"AI_BR_VIRTUAL_CLASS\",\n",
        "      \"Description\":\"AI_BR_VIRTUAL_CLASS\",\n",
        "      \"PrincipalId\":\"group/d-9f673c79a6/cc703591-a7f4-4382-bb5e-e1849779d2f2\"\n",
        "   }\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "-KLKS8ydcw2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_names = [item[\"GroupName\"] for item in l]\n",
        "print(group_names)"
      ],
      "metadata": {
        "id": "8J1LsqWNc-j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [('tore',)]\n",
        "b= ''.join([x[0] for x in a])\n",
        "print(b)\n",
        "rs=[x[0] for x in a]\n",
        "print(rs)\n",
        "values = ''.join(map(str, rs))\n",
        "print(values)\n",
        "# rs_str= ''.join([x[0] for x in rs])\n",
        "# values=rs_str\n",
        "# values = ''.join(map(str, rs))"
      ],
      "metadata": {
        "id": "xxHd9_xMpR_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime,timedelta\n",
        "today = datetime.datetime.now()+ timedelta(days=-1)\n",
        "DateFormat= today.strftime('%Y%m%d')\n",
        "print(DateFormat)"
      ],
      "metadata": {
        "id": "N0OLbNhdgODH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cast(dt as date) BETWEEN date_sub(CAST(current_timestamp() as DATE), 1) AND date_sub(CAST(current_timestamp() as DATE), 0)"
      ],
      "metadata": {
        "id": "3GIbGNkugafb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "TOEEGBunJ4Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"MedianSalary\").getOrCreate()\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    (\"John\", 50000),\n",
        "    (\"Jane\", 60000),\n",
        "    (\"Doe\", 55000),\n",
        "    (\"Dp\", 56000),\n",
        "    (\"Smith\", 52000),\n",
        "    (\"Eve\", 58000)\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "columns = [\"employee_name\", \"salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Register the DataFrame as a SQL temporary view\n",
        "df.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "# Calculate the median salary using SQL\n",
        "# First, we need to get the count of salaries to determine if we need to take the average of two middle values\n",
        "query_median = \"\"\"\n",
        "WITH salary_ranked AS (\n",
        "    SELECT salary, ROW_NUMBER() OVER (ORDER BY salary) AS row_num, COUNT(*) OVER () AS total_rows\n",
        "    FROM employees\n",
        ")\n",
        "SELECT\n",
        "    AVG(salary) AS median_salary\n",
        "FROM\n",
        "    salary_ranked\n",
        "WHERE\n",
        "    row_num IN (FLOOR((total_rows + 1) / 2), CEIL((total_rows + 1) / 2))\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "median_salary_df = spark.sql(query_median)\n",
        "median_salary_df.show()\n",
        "median_salary = median_salary_df.collect()[0]['median_salary']\n",
        "\n",
        "# Use SQL to find the employee with the closest salary to the median salary, but not the median salary\n",
        "query_closest = f\"\"\"\n",
        "WITH filtered_employees AS (\n",
        "    SELECT\n",
        "        employee_name,\n",
        "        salary,\n",
        "        ABS(salary - {median_salary}) AS abs_diff\n",
        "    FROM\n",
        "        employees\n",
        "    WHERE\n",
        "        salary != {median_salary}\n",
        ")\n",
        "SELECT\n",
        "    employee_name,\n",
        "    salary,\n",
        "    abs_diff\n",
        "FROM\n",
        "    filtered_employees\n",
        "ORDER BY\n",
        "    abs_diff\n",
        "LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "closest_employee_df = spark.sql(query_closest)\n",
        "\n",
        "# Display the median salary and the closest employee's details\n",
        "print(f\"Median Salary: {median_salary}\")\n",
        "closest_employee_df.show()\n"
      ],
      "metadata": {
        "id": "RyFyFCLYJ2hL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}